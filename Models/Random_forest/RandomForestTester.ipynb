{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForestTester.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "af2O32FzcoiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "80c4f273-3b57-46d0-9a78-0ea95cd8f0eb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as mt\n",
        "import sklearn as sk1\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import math \n",
        "import seaborn as plt1\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "!pip install missingpy\n",
        "import missingpy as imput_helper\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting missingpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/998d04d27054b58f0974b5f09f8457778a0a72d4355e0b7ae877b6cfb850/missingpy-0.2.0-py3-none-any.whl (49kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FylH5U1icN8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "work_dat_notDead_large = pd.read_csv(\"work_dat_notDead_large-Final model specific.csv\")\n",
        "\n",
        "\n",
        "work_dat_notDead_large_backup = work_dat_notDead_large.copy()\n",
        "\n",
        "work_dat_notDead_large = work_dat_notDead_large.loc[work_dat_notDead_large['InscClaimAmtReimbursed']>20000,:].copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWHGoFEIcbEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying models\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "import lightgbm as lgbm\n",
        "from sklearn.preprocessing import RobustScaler  # Here we are applying the RobustScaler to minimize variance and outliers in the data and make them more standard\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#work_dat_notDead_large = work_dat_notDead_large.drop(columns=['BeneID'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "ClassFraud_y = work_dat_notDead_large['PotentialFraud'].copy()\n",
        "ClassFraud_x = work_dat_notDead_large[work_dat_notDead_large.columns.difference(['PotentialFraud'])]\n",
        "\n",
        "scaler.fit(ClassFraud_x)\n",
        "\n",
        "# save the scaler\n",
        "pickle.dump(scaler, open('Random_Forest_scaler.pkl', 'wb'))\n",
        "\n",
        "ClassFraud_x_Scaled = scaler.transform(ClassFraud_x)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(ClassFraud_x_Scaled, ClassFraud_y, test_size=0.33)\n",
        "\n",
        "# Scaling data by using preprocessing tools for a better results:\n",
        "\n",
        "######1>> Fisher linear model:\n",
        "\n",
        "#model = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "#attphy_x_labelcode,label_x = pd.factorize(attphy_x)\n",
        "#X_test_labelcode = pd.factorize(X_test)\n",
        "#attphy_y_labelcode,label_y = pd.factorize(attphy_y)\n",
        "#y_test_labelcode = pd.factorize(y_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmCNKRbcisF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
        "\n",
        "param_grid = { \n",
        "    'max_features': ['auto', 'log2']\n",
        "}\n",
        "\n",
        "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n",
        "CV_rfc.fit(X_train, y_train)\n",
        "#print CV_rfc.best_params_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEWw3_Kese0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the scaler\n",
        "pickle.dump(rfc, open('random_Forest_model.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}